<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Lynn&#39;s Blog</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-09-14T07:24:00.000Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Lynn Zhou</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kubernetes集群搭建(1)</title>
    <link href="http://example.com/2021/09/14/Kubernetes%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA(1)/"/>
    <id>http://example.com/2021/09/14/Kubernetes%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA(1)/</id>
    <published>2021-09-14T06:35:42.000Z</published>
    <updated>2021-09-14T07:24:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>这次打算尝试使用<code>kubeadm</code>来从头搭建一个<code>Kubernetes集群</code>，并且记录下整个过程以及中途遇到的问题。</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>这次的搭建需要两台虚拟机，一台作为<code>Master节点</code>而另一台作为<code>Node节点</code>方便后续进行更多的集群相关的测试。</p><p>云服务器：</p><ul><li>  AWS t2.large(2vCPU 8GiB) *2</li></ul><p>搭建工具：</p><ul><li>  kubeadm</li></ul><p>kubeadm 是一个可以帮助一键搭建 Kubernetes 集群的工具。</p><h1 id="搭建-Master-节点"><a href="#搭建-Master-节点" class="headerlink" title="搭建 Master 节点"></a>搭建 Master 节点</h1><h2 id="1-安装-kubeadm-以及相关工具"><a href="#1-安装-kubeadm-以及相关工具" class="headerlink" title="#1 安装 kubeadm 以及相关工具"></a>#1 安装 kubeadm 以及相关工具</h2><p>首先需要配置云服务器，安装需要的工具。</p><pre><code class="bash">$sudo apt-get update$sudo apt-get install gnupg$curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -OK</code></pre><p>需要将 Kubernetes 官方源添加到本地。</p><pre><code>#/etc/apt/sources.list.d/kubernetes.listdeb http://apt.kubernetes.io/ kubernetes-xenial main</code></pre><p>将以上文件（/etc/apt/sources.list.d/kubernetes.list）添加了之后，运行以下命令可以看到此时 Kubernetes 的源已经被添加进来。</p><pre><code class="bash">$sudo apt-get update...Get:4 https://packages.cloud.google.com/apt kubernetes-xenial InRelease [9383 B]Get:6 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 Packages [49.4 kB]...</code></pre><p>在完成了以上的配置之后即可开始安装<code>kubelet</code>，<code>kubectl</code>以及<code>kubeadm</code></p><p><code>kubeadm</code>需要使用<code>kubelet</code>服务来以容器方式部署和启动 Kubernetes 的主要服务，所以需要安装并先启动 kubelet 服务。<br>而<code>kubectl</code>则是客户端命令行工具，在集群搭建完成之后可以通过它查看集群信息与状态。</p><pre><code class="bash"># 安装kubelet，kubectl以及kubeadm$sudo apt-get install kubelet kubectl kubeadm</code></pre><p>要启动 kubelet 需要先安装并启动<code>docker</code></p><pre><code class="bash">$curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/debian/gpg | sudo apt-key add –OK# 要安装了 software-properties-common 才能使用 add-apt-repository$sudo apt-get install software-properties-common$sudo add-apt-repository \&quot;deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/debian \$(lsb_release -cs) \stable&quot;# 安装docker$sudo apt-get install docker-ce</code></pre><p>完成了以上所需工具的安装后就可以开始按顺序启动它们。</p><pre><code class="bash">#启动docker和kubelet$systemctl start docker$systemctl enable kubelet$systemctl start kubelet</code></pre><p>在 docker 和 kubelet 都在服务器上正常启动后，可使用<code>kubeadm init</code>命令打印<code>kubeadm</code>的默认配置.</p><pre><code class="bash">#输出kubeadm默认配置$kubeadm config print init-defaults#将kubeadm默认配置保存到文件中方便做自定义修改$kubeadm config print init-defaults &gt;&gt; init.default.yaml</code></pre><p>以下是<code>kubeadm</code>打印出来的默认配置:</p><pre><code>#init.default.yamlapiVersion: kubeadm.k8s.io/v1beta3bootstrapTokens:-   groups:    -   system:bootstrappers:kubeadm:default-node-token        token: abcdef.0123456789abcdef        ttl: 24h0m0s        usages:    -   signing    -   authentication        kind: InitConfiguration        localAPIEndpoint:        advertiseAddress: 1.2.3.4        bindPort: 6443        nodeRegistration:        criSocket: /var/run/dockershim.sock        imagePullPolicy: IfNotPresent        name: node        taints: null---apiServer:timeoutForControlPlane: 4m0sapiVersion: kubeadm.k8s.io/v1beta3certificatesDir: /etc/kubernetes/pkiclusterName: kubernetescontrollerManager: &#123;&#125;dns: &#123;&#125;etcd:local:dataDir: /var/lib/etcdimageRepository: k8s.gcr.iokind: ClusterConfigurationkubernetesVersion: 1.22.0networking:dnsDomain: cluster.localserviceSubnet: 10.96.0.0/12scheduler: &#123;&#125;</code></pre><p>用以下命令可以查看镜像列表:</p><pre><code class="bash">$kubeadm config images listk8s.gcr.io/kube-apiserver:v1.22.1k8s.gcr.io/kube-controller-manager:v1.22.1k8s.gcr.io/kube-scheduler:v1.22.1k8s.gcr.io/kube-proxy:v1.22.1k8s.gcr.io/pause:3.5k8s.gcr.io/etcd:3.5.0-0k8s.gcr.io/coredns/coredns:v1.8.4</code></pre><p>可以使用<code>kubeadm config images pull</code>命令将这些镜像提前拉下来。就算不提前拉取，在后续步骤运行<code>kubeadm init</code>命令的时候也会自动进行拉取。</p><h2 id="2-使用-kubeadm-安装-Master-节点"><a href="#2-使用-kubeadm-安装-Master-节点" class="headerlink" title="#2 使用 kubeadm 安装 Master 节点"></a>#2 使用 kubeadm 安装 Master 节点</h2><p>使用以下命令就可直接安装 Master 节点：</p><pre><code class="bash">$sudo kubeadm init --pod-network-cidr=172.30.0.0/16</code></pre><p>这里注意一定要加上后面的<code>—pod-network-cidr</code>参数，否则在安装 flannel（网络插件）时会报以下错误：</p><pre><code>E0913 19:45:12.323393 1 main.go:293] Error registering network: failed to acquire lease: node &quot;ip-172-31-40-163&quot; pod cidr not assigned</code></pre><p>这次我没有修改默认的配置，如果有自定义配置，可以运行</p><pre><code class="bash">$sudo kubeadm init –config=&lt;config_file_path&gt;</code></pre><p>安装完成后会得到以下相关提示:</p><pre><code>Your Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user:mkdir -p $HOME/.kube  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config  sudo chown $(id -u):$(id -g) $HOME/.kube/configAlternatively, if you are the root user, you can run:export KUBECONFIG=/etc/kubernetes/admin.confYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 172.31.40.163:6443 --token 61gwee.be4wj16mlyjsahaj \ --discovery-token-ca-cert-hash sha256:97ea59547a4cca2fbcf62360b3561c6e27dd4e1a294533505490391dab872daf</code></pre><p>根据提示可以运行以下命令，这些命令是为了方便用户通过<code>kubectl</code>访问集群，<code>config</code>文件里配置了访问集群的入口，用户以及 token 等。</p><pre><code class="bash">$mkdir -p $HOME/.kube$sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config$sudo chown $(id -u):$(id -g) $HOME/.kube/config</code></pre><p>完成配置后就可以使用 kubectl 访问集群了。</p><p>使用<code>kubectl get node</code>可以看到，目前<code>master node</code>的状态是<code>Not Ready</code>。</p><pre><code>NAME             STATUS     ROLES                AGE    VERSIONip-172-31-40-163 NotReady   control-plane,master 14m    v1.22.1</code></pre><p>使用<code>kubectl get node &lt;node_name&gt; -o yaml</code>(或者<code>kubectl describe node &lt;node_name&gt;</code>)可以查看具体原因：</p><pre><code class="yaml">...message: &#39;container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReadymessage:docker: network plugin is not ready: cni config uninitialized&#39;reason: KubeletNotReadystatus: &quot;False&quot;...</code></pre><p>这是由于<code>kubeadm</code>的安装过程<strong>不涉及</strong><code>网络插件（CNI)</code>的初始化，所以集群没有网络功能。</p><pre><code class="bash">$kubectl get pod --all-namespacesNAMESPACE   NAME                        READY   STATUS  RESTARTS AGEkube-system coredns-78fcd69978-59b4t     0/1     Pending 0       10mkube-system coredns-78fcd69978-hc8qn     0/1     Pending 0       10mkube-system etcd-ip-172-31-40-163        1/1     Running 3       10mkube-system kube-apiserver-ip-172-...    1/1     Running 2       10mkube-system kube-controller-manager-...  1/1     Running 2       10mkube-system kube-proxy-dzklf             1/1     Running 0       10mkube-system kube-scheduler-ip-172-...    1/1     Running 3       10m</code></pre><p>可以观察到<code>kubadm</code>已经为<code>master 节点</code>启动了<code>coredns</code>,<code>etcd</code>,<code>kube-apiserver</code>,<code>kube-controller-manager</code>,<code>kube-proxy</code>以及 <code>kube-scheduler</code>了。<br>并且与网络相关<code>coredns</code>由于没有网络也无法正常启动。</p><h2 id="3-安装网络插件-Flannel"><a href="#3-安装网络插件-Flannel" class="headerlink" title="#3 安装网络插件 Flannel"></a>#3 安装网络插件 Flannel</h2><p>首先下载在 Kubernetes 集群内安装<code>flanner</code>所需的配置文件，里面包括了启动该服务所需的所有资源的配置</p><pre><code class="bash">$wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</code></pre><p>使用下载的 Yaml 文件在集群内启动所有相关资源</p><pre><code class="bash">$kubectl apply -f kube-flannel.ymlpodsecuritypolicy.policy/psp.flannel.unprivileged createdclusterrole.rbac.authorization.k8s.io/flannel createdclusterrolebinding.rbac.authorization.k8s.io/flannel createdserviceaccount/flannel createdconfigmap/kube-flannel-cfg createddaemonset.apps/kube-flannel-ds created</code></pre><p>现在查看<code>pod</code>的状态可以发现所有的<code>pod</code>都正常运行(<code>Running</code>)中</p><pre><code class="bash">$ kubectl get pod --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system coredns-78fcd69978-xx27f 1/1 Running 0 3m40skube-system coredns-78fcd69978-zxnw5 1/1 Running 0 3m40skube-system etcd-ip-172-31-40-163 1/1 Running 4 3m54skube-system kube-apiserver-ip-172-31-40-163 1/1 Running 3 3m54skube-system kube-controller-manager-ip-172-31-40-163 1/1 Running 0 3m57skube-system kube-flannel-ds-26tcn 1/1 Running 0 5skube-system kube-proxy-8c4md 1/1 Running 0 3m40skube-system kube-scheduler-ip-172-31-40-163 1/1 Running 4 3m54s</code></pre><p>而<code>master 节点</code>也切换到了<code>Ready</code>的状态</p><pre><code class="bash">$ kubectl get nodeNAME                STATUS  ROLES                   AGE     VERSIONip-172-31-40-163    Ready   control-plane,master    4m47s   v1.22.1</code></pre><h1 id="错误及解决方案"><a href="#错误及解决方案" class="headerlink" title="错误及解决方案"></a>错误及解决方案</h1><h2 id="1-docker-连接-Docker-daemon-socket-失败"><a href="#1-docker-连接-Docker-daemon-socket-失败" class="headerlink" title="#1 docker 连接 Docker daemon socket 失败"></a>#1 docker 连接 Docker daemon socket 失败</h2><p>运行<code>docker info</code>命令时得到以下错误：</p><pre><code>ERROR: Got permission denied while trying to connect to the Docker daemon socket ...</code></pre><p>需要确认 docker 组已经创建并且当前使用的用户在这个组内。</p><pre><code class="bash">$sudo groupadd docker$sudo gpasswd -a &lt;username&gt; docker$newgrp docker$systemctl restart docker</code></pre><p>完成以上步骤后，再次运行<code>docker info</code>命令可以正确得到所需信息。</p><h2 id="2-Kubelet-启动失败"><a href="#2-Kubelet-启动失败" class="headerlink" title="#2 Kubelet 启动失败"></a>#2 Kubelet 启动失败</h2><p>用<code>systemctl status kubelet</code>命令获得进程号后，再用<code>journalctl \_PID=&lt;进程号&gt;|vim – </code>查看日志，获得了以下信息：</p><pre><code class="bash">Sep 13 17:30:09 ip-172-31-40-163 kubelet[18094]: E0913 17:30:09.620375 18094 server.go:294] &quot;Failed to run kubelet&quot; err=&quot;failed to run Kubelet: misconfiguration: kubelet cgroup driver: \&quot;systemd\&quot; is different from docker cgroup driver: \&quot;cgroupfs\&quot;&quot;</code></pre><p>原因是<code>docker</code>和<code>kubelet</code>使用的<code>cgroup driver</code>不一样，一个是<code>systemd</code>，一个是<code>cgroupfs</code>。根据 Kubernetes 官网文档：</p><blockquote><p><code>systemd driver</code> is <strong>recommended</strong> for <code>kubeadm</code> based setups instead of the <code>cgroupfs driver</code>, because kubeadm manages the kubelet as a systemd service.</p></blockquote><p><code>systemd</code>是比较推荐的,也是 kubeadm 默认设置的 cgroup drive。（据说 systemd 更安全）所以这里我统一设置成使用 systemd。也就是需要把 <code>docker</code> 的<code>cgroup driver</code>更改成<code>systemd</code></p><p>修改<code>/etc/docker/daemon.json</code>（或创建）</p><pre><code>#/etc/docker/daemon.json&#123;&quot;exec-opts&quot;:[&quot;native.cgroupdriver=systemd&quot;]&#125;</code></pre><p>在完成修改之后，用以下命令更新配置并重启 docker</p><pre><code class="bash">$systemctl daemon-reload$systemctl restart docker</code></pre><p>重启后使用<code>docker info</code>命令可获得 docker 的所有相关信息,可以确认 docker 的<code>cgroup driver</code>已经换成了<code>systemd</code>。</p><pre><code class="bash">$ docker info...Logging Driver: json-fileCgroup Driver: systemdCgroup Version: 1...</code></pre><p>此时再确认 kubelet 的状态可以看到 kubelet 已经自动重启并正常运行。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这次打算尝试使用&lt;code&gt;kubeadm&lt;/code&gt;来从头搭建一个&lt;code&gt;Kubernetes集群&lt;/code&gt;，并且记录下整个过程以及中途遇到的问题。&lt;/p&gt;
&lt;h1 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; tit</summary>
      
    
    
    
    
    <category term="Kubernetes" scheme="http://example.com/tags/Kubernetes/"/>
    
  </entry>
  
</feed>
